"""
Scholarly Export Formatters for LingFrame.

Provides export formats suitable for academic publication and
digital humanities research:

- LaTeX: For academic papers and theses
- TEI-XML: For Text Encoding Initiative compliant digital editions
- CONLL: For computational linguistics annotation sharing

These exports are designed for reproducibility and integration with
established scholarly workflows.
"""

from __future__ import annotations

import json
import re
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
from xml.etree import ElementTree as ET
from xml.dom import minidom


@dataclass
class ExportMetadata:
    """Metadata for scholarly exports."""
    title: str
    author: str = "LingFrame Analysis"
    date: str = field(default_factory=lambda: datetime.now().strftime("%Y-%m-%d"))
    version: str = "1.0.0"
    source_file: Optional[str] = None
    analysis_config: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "author": self.author,
            "date": self.date,
            "version": self.version,
            "source_file": self.source_file,
            "analysis_config": self.analysis_config,
        }


class ScholarlyExporter(ABC):
    """Base class for scholarly export formats."""

    format_name: str = "base"
    file_extension: str = ".txt"

    @abstractmethod
    def export(
        self,
        analysis_output: Dict[str, Any],
        metadata: ExportMetadata,
    ) -> str:
        """Export analysis to formatted string."""
        pass

    def export_to_file(
        self,
        analysis_output: Dict[str, Any],
        metadata: ExportMetadata,
        output_path: Path,
    ) -> Path:
        """Export analysis to file."""
        content = self.export(analysis_output, metadata)
        output_path = output_path.with_suffix(self.file_extension)
        output_path.write_text(content, encoding="utf-8")
        return output_path


class LaTeXExporter(ScholarlyExporter):
    """
    Export analysis results to LaTeX format.

    Produces a structured LaTeX document suitable for inclusion
    in academic papers. Includes:
    - Document preamble with metadata
    - Analysis summary table
    - Per-step detailed findings
    - Evidence citations with text references
    - Recommendations section
    """

    format_name = "latex"
    file_extension = ".tex"

    def __init__(self, document_class: str = "article"):
        self.document_class = document_class

    def export(
        self,
        analysis_output: Dict[str, Any],
        metadata: ExportMetadata,
    ) -> str:
        """Export analysis to LaTeX document."""
        lines = []

        # Document preamble
        lines.extend([
            f"\\documentclass{{{self.document_class}}}",
            "\\usepackage[utf8]{inputenc}",
            "\\usepackage{booktabs}",
            "\\usepackage{longtable}",
            "\\usepackage{hyperref}",
            "\\usepackage{xcolor}",
            "",
            f"\\title{{{self._escape(metadata.title)}}}",
            f"\\author{{{self._escape(metadata.author)}}}",
            f"\\date{{{metadata.date}}}",
            "",
            "\\begin{document}",
            "\\maketitle",
            "",
        ])

        # Abstract/Summary
        summary = analysis_output.get("summary", {})
        overall_score = summary.get("overall_score", "N/A")

        lines.extend([
            "\\begin{abstract}",
            f"This document presents a rhetorical analysis generated by LingFrame v{metadata.version}. ",
            f"The overall heuristic score is {overall_score:.1f}/100, based on pattern-matching ",
            "against predefined linguistic markers. Scores indicate pattern density, not ",
            "validated quality assessments.",
            "\\end{abstract}",
            "",
        ])

        # Summary table
        lines.extend(self._export_summary_table(analysis_output))

        # Step details
        lines.extend(self._export_step_details(analysis_output))

        # Methodology note
        lines.extend([
            "\\section{Methodology Note}",
            "\\label{sec:methodology}",
            "",
            "This analysis uses heuristic pattern matching against predefined linguistic markers. ",
            "Scores represent pattern density indicators, not validated measurements of ",
            "rhetorical quality. The methodology relies on:",
            "\\begin{itemize}",
            "\\item Regex-based pattern detection for evidence, emotional, and authority markers",
            "\\item Weighted aggregation across atomization levels (sentence 35\\%, paragraph 30\\%, etc.)",
            "\\item Optional LLM enhancement for qualitative insights",
            "\\end{itemize}",
            "",
            "For full methodology and limitations, see the LingFrame documentation.",
            "",
        ])

        # End document
        lines.extend([
            "\\end{document}",
        ])

        return "\n".join(lines)

    def _escape(self, text: str) -> str:
        """Escape special LaTeX characters."""
        if not text:
            return ""
        replacements = [
            ("\\", "\\textbackslash{}"),
            ("&", "\\&"),
            ("%", "\\%"),
            ("$", "\\$"),
            ("#", "\\#"),
            ("_", "\\_"),
            ("{", "\\{"),
            ("}", "\\}"),
            ("~", "\\textasciitilde{}"),
            ("^", "\\textasciicircum{}"),
        ]
        for old, new in replacements:
            text = text.replace(old, new)
        return text

    def _export_summary_table(self, analysis_output: Dict[str, Any]) -> List[str]:
        """Export summary as LaTeX table."""
        lines = [
            "\\section{Analysis Summary}",
            "\\label{sec:summary}",
            "",
            "\\begin{table}[h]",
            "\\centering",
            "\\begin{tabular}{lrl}",
            "\\toprule",
            "Step & Score & Phase \\\\",
            "\\midrule",
        ]

        # Extract steps from phases
        phases = analysis_output.get("phases", {})
        for phase_name, phase_data in phases.items():
            if isinstance(phase_data, dict):
                for step_name, step_data in phase_data.items():
                    if isinstance(step_data, dict) and "score" in step_data:
                        score = step_data.get("score", 0)
                        lines.append(
                            f"{self._escape(step_name.replace('_', ' ').title())} & "
                            f"{score:.1f} & {self._escape(phase_name.title())} \\\\"
                        )

        # Overall
        summary = analysis_output.get("summary", {})
        overall = summary.get("overall_score", 0)
        lines.extend([
            "\\midrule",
            f"\\textbf{{Overall}} & \\textbf{{{overall:.1f}}} & \\\\",
            "\\bottomrule",
            "\\end{tabular}",
            f"\\caption{{Rhetorical Analysis Scores (0-100 scale, pattern density)}}",
            "\\label{tab:scores}",
            "\\end{table}",
            "",
        ])

        return lines

    def _export_step_details(self, analysis_output: Dict[str, Any]) -> List[str]:
        """Export detailed step findings."""
        lines = [
            "\\section{Detailed Findings}",
            "\\label{sec:findings}",
            "",
        ]

        phases = analysis_output.get("phases", {})
        for phase_name, phase_data in phases.items():
            if isinstance(phase_data, dict):
                lines.append(f"\\subsection{{{self._escape(phase_name.title())} Phase}}")
                lines.append("")

                for step_name, step_data in phase_data.items():
                    if isinstance(step_data, dict) and "score" in step_data:
                        lines.extend(self._export_single_step(step_name, step_data))

        return lines

    def _export_single_step(self, step_name: str, step_data: Dict[str, Any]) -> List[str]:
        """Export a single step's findings."""
        lines = [
            f"\\subsubsection{{{self._escape(step_name.replace('_', ' ').title())}}}",
            "",
            f"Score: {step_data.get('score', 0):.1f}/100",
            "",
        ]

        # Findings
        findings = step_data.get("findings", [])
        if findings:
            lines.append("\\textbf{Findings:}")
            lines.append("\\begin{itemize}")
            for finding in findings[:5]:  # Limit to 5
                desc = finding.get("description", "")
                ftype = finding.get("type", "observation")
                lines.append(f"\\item [{ftype.title()}] {self._escape(desc)}")
            lines.append("\\end{itemize}")
            lines.append("")

        # Recommendations
        recommendations = step_data.get("recommendations", [])
        if recommendations:
            lines.append("\\textbf{Recommendations:}")
            lines.append("\\begin{enumerate}")
            for rec in recommendations[:3]:  # Limit to 3
                lines.append(f"\\item {self._escape(rec)}")
            lines.append("\\end{enumerate}")
            lines.append("")

        # Evidence (if explainability data present)
        explanation = step_data.get("explanation", {})
        evidence = explanation.get("evidence", [])
        if evidence:
            lines.append("\\textbf{Sample Evidence:}")
            lines.append("\\begin{quote}")
            for ev in evidence[:3]:  # Show top 3
                text = ev.get("text", "")
                atom_id = ev.get("atom_id", "")
                lines.append(f"``{self._escape(text)}'' ({self._escape(atom_id)})")
            lines.append("\\end{quote}")
            lines.append("")

        return lines


class TEIXMLExporter(ScholarlyExporter):
    """
    Export analysis to TEI-XML format.

    Produces Text Encoding Initiative compliant XML suitable for
    digital humanities research. Structure includes:
    - TEI header with metadata
    - Text body with analysis annotations
    - Stand-off annotations for findings
    """

    format_name = "tei-xml"
    file_extension = ".xml"

    def export(
        self,
        analysis_output: Dict[str, Any],
        metadata: ExportMetadata,
    ) -> str:
        """Export analysis to TEI-XML format."""
        # Create root element with TEI namespace
        tei = ET.Element("TEI", xmlns="http://www.tei-c.org/ns/1.0")

        # TEI Header
        header = self._create_header(metadata, analysis_output)
        tei.append(header)

        # Text body
        text = self._create_text_body(analysis_output)
        tei.append(text)

        # Stand-off annotations
        standoff = self._create_standoff(analysis_output)
        tei.append(standoff)

        # Pretty print
        xml_str = ET.tostring(tei, encoding="unicode")
        dom = minidom.parseString(xml_str)
        return dom.toprettyxml(indent="  ")

    def _create_header(
        self,
        metadata: ExportMetadata,
        analysis_output: Dict[str, Any],
    ) -> ET.Element:
        """Create TEI header."""
        header = ET.Element("teiHeader")

        # File description
        file_desc = ET.SubElement(header, "fileDesc")

        # Title statement
        title_stmt = ET.SubElement(file_desc, "titleStmt")
        title = ET.SubElement(title_stmt, "title")
        title.text = metadata.title
        author = ET.SubElement(title_stmt, "author")
        author.text = metadata.author

        # Publication statement
        pub_stmt = ET.SubElement(file_desc, "publicationStmt")
        publisher = ET.SubElement(pub_stmt, "publisher")
        publisher.text = "LingFrame Rhetorical Analysis"
        date = ET.SubElement(pub_stmt, "date")
        date.text = metadata.date

        # Source description
        source_desc = ET.SubElement(file_desc, "sourceDesc")
        bibl = ET.SubElement(source_desc, "bibl")
        if metadata.source_file:
            bibl.text = f"Analysis of: {metadata.source_file}"
        else:
            bibl.text = "LingFrame automated analysis"

        # Encoding description
        encoding_desc = ET.SubElement(header, "encodingDesc")
        project_desc = ET.SubElement(encoding_desc, "projectDesc")
        p = ET.SubElement(project_desc, "p")
        p.text = (
            "This TEI document contains rhetorical analysis generated by LingFrame. "
            "Scores are heuristic indicators based on pattern matching, not validated "
            "quality measurements. See documentation for methodology and limitations."
        )

        # Profile description with analysis summary
        profile_desc = ET.SubElement(header, "profileDesc")
        text_class = ET.SubElement(profile_desc, "textClass")

        # Add scores as keywords
        keywords = ET.SubElement(text_class, "keywords", scheme="lingframe")
        summary = analysis_output.get("summary", {})
        for key, value in summary.items():
            if isinstance(value, (int, float)):
                term = ET.SubElement(keywords, "term", type=key)
                term.text = f"{value:.1f}"

        return header

    def _create_text_body(self, analysis_output: Dict[str, Any]) -> ET.Element:
        """Create TEI text body with analysis summary."""
        text = ET.Element("text")
        body = ET.SubElement(text, "body")

        # Analysis summary
        div_summary = ET.SubElement(body, "div", type="analysis-summary")
        head = ET.SubElement(div_summary, "head")
        head.text = "Rhetorical Analysis Summary"

        summary = analysis_output.get("summary", {})
        overall = summary.get("overall_score", 0)

        p = ET.SubElement(div_summary, "p")
        p.text = f"Overall heuristic score: {overall:.1f}/100"

        # Phase summaries
        phases = analysis_output.get("phases", {})
        for phase_name, phase_data in phases.items():
            if isinstance(phase_data, dict):
                div_phase = ET.SubElement(body, "div", type="phase")
                div_phase.set("n", phase_name)

                phase_head = ET.SubElement(div_phase, "head")
                phase_head.text = phase_name.title()

                for step_name, step_data in phase_data.items():
                    if isinstance(step_data, dict) and "score" in step_data:
                        div_step = ET.SubElement(div_phase, "div", type="step")
                        div_step.set("n", step_name)

                        step_head = ET.SubElement(div_step, "head")
                        step_head.text = step_name.replace("_", " ").title()

                        score_p = ET.SubElement(div_step, "p")
                        score_p.text = f"Score: {step_data.get('score', 0):.1f}"

                        # Findings as list
                        findings = step_data.get("findings", [])
                        if findings:
                            finding_list = ET.SubElement(div_step, "list", type="findings")
                            for finding in findings[:5]:
                                item = ET.SubElement(finding_list, "item")
                                item.set("type", finding.get("type", "observation"))
                                item.text = finding.get("description", "")

        return text

    def _create_standoff(self, analysis_output: Dict[str, Any]) -> ET.Element:
        """Create stand-off annotation for evidence links."""
        standoff = ET.Element("standOff")

        # Evidence annotations
        annotation_block = ET.SubElement(standoff, "listAnnotation")
        annotation_block.set("type", "evidence")

        phases = analysis_output.get("phases", {})
        ann_id = 1

        for phase_name, phase_data in phases.items():
            if isinstance(phase_data, dict):
                for step_name, step_data in phase_data.items():
                    if isinstance(step_data, dict):
                        explanation = step_data.get("explanation", {})
                        evidence = explanation.get("evidence", [])

                        for ev in evidence[:10]:  # Limit per step
                            ann = ET.SubElement(annotation_block, "annotation")
                            ann.set("{http://www.w3.org/XML/1998/namespace}id", f"ann_{ann_id}")

                            target = ET.SubElement(ann, "target")
                            target.text = ev.get("atom_id", "")

                            body = ET.SubElement(ann, "body")

                            term = ET.SubElement(body, "term", type="category")
                            term.text = ev.get("category", "")

                            quote = ET.SubElement(body, "quote")
                            quote.text = ev.get("text", "")

                            note = ET.SubElement(body, "note", type="context")
                            note.text = ev.get("context", "")

                            ann_id += 1

        return standoff


class CONLLExporter(ScholarlyExporter):
    """
    Export analysis to CONLL-like format.

    Produces tab-separated annotation file suitable for
    computational linguistics tools. Format:
    TOKEN  LEMMA  POS  CATEGORY  PATTERN_GROUP  SCORE
    """

    format_name = "conll"
    file_extension = ".conll"

    def export(
        self,
        analysis_output: Dict[str, Any],
        metadata: ExportMetadata,
    ) -> str:
        """Export evidence annotations to CONLL format."""
        lines = [
            f"# LingFrame Analysis Export",
            f"# Title: {metadata.title}",
            f"# Date: {metadata.date}",
            f"# Version: {metadata.version}",
            f"# Format: TOKEN\\tATOM_ID\\tCATEGORY\\tPATTERN_GROUP\\tSTEP",
            "",
        ]

        phases = analysis_output.get("phases", {})

        for phase_name, phase_data in phases.items():
            if isinstance(phase_data, dict):
                for step_name, step_data in phase_data.items():
                    if isinstance(step_data, dict):
                        explanation = step_data.get("explanation", {})
                        evidence = explanation.get("evidence", [])

                        for ev in evidence:
                            token = ev.get("text", "_").replace("\t", " ")  # allow-secret
                            atom_id = ev.get("atom_id", "_")
                            category = ev.get("category", "_")
                            pattern_group = ev.get("pattern_group", "_")

                            lines.append(
                                f"{token}\t{atom_id}\t{category}\t{pattern_group}\t{step_name}"
                            )

        return "\n".join(lines)


# Factory function
def get_exporter(format_name: str) -> ScholarlyExporter:
    """Get exporter by format name."""
    exporters = {
        "latex": LaTeXExporter,
        "tei": TEIXMLExporter,
        "tei-xml": TEIXMLExporter,
        "conll": CONLLExporter,
    }

    if format_name.lower() not in exporters:
        raise ValueError(
            f"Unknown export format: {format_name}. "
            f"Available: {list(exporters.keys())}"
        )

    return exporters[format_name.lower()]()


def export_analysis(
    analysis_output: Dict[str, Any],
    format_name: str,
    title: str,
    output_path: Optional[Path] = None,
    **metadata_kwargs,
) -> str:
    """
    Export analysis to scholarly format.

    Args:
        analysis_output: Analysis result dictionary
        format_name: Export format (latex, tei, conll)
        title: Document title
        output_path: Optional file path to write
        **metadata_kwargs: Additional metadata (author, date, etc.)

    Returns:
        Formatted string (also writes to file if output_path provided)
    """
    exporter = get_exporter(format_name)
    metadata = ExportMetadata(title=title, **metadata_kwargs)

    content = exporter.export(analysis_output, metadata)

    if output_path:
        output_path = Path(output_path)
        exporter.export_to_file(analysis_output, metadata, output_path)

    return content
