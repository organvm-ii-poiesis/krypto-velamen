{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Exploration Notebook\n",
    "\n",
    "This notebook provides an interactive environment for exploring your atomized corpus.\n",
    "\n",
    "## What you can do:\n",
    "- Load and inspect the atomized corpus structure\n",
    "- Browse themes, paragraphs, and sentences\n",
    "- View statistics at each atomization level\n",
    "- Search for specific content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and load the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add framework to path\n",
    "FRAMEWORK_ROOT = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(FRAMEWORK_ROOT))\n",
    "\n",
    "# Import framework modules\n",
    "from framework.core import Atomizer, Corpus, AtomLevel\n",
    "from framework.core.ontology import Atom, Document\n",
    "\n",
    "print(f\"Framework root: {FRAMEWORK_ROOT}\")\n",
    "print(\"Framework modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these for your project\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "PROJECT_NAME = PROJECT_DIR.name\n",
    "\n",
    "# Find atomized corpus file\n",
    "RAW_DIR = PROJECT_DIR / \"data\" / \"raw\"\n",
    "CORPUS_FILE = RAW_DIR / f\"{PROJECT_NAME}_atomized.json\"\n",
    "\n",
    "print(f\"Project: {PROJECT_NAME}\")\n",
    "print(f\"Corpus file: {CORPUS_FILE}\")\n",
    "print(f\"Exists: {CORPUS_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the atomized corpus\n",
    "if CORPUS_FILE.exists():\n",
    "    corpus = Atomizer.load_json(CORPUS_FILE)\n",
    "    print(f\"Loaded corpus: {corpus.name}\")\n",
    "    print(f\"Documents: {corpus.total_documents}\")\n",
    "else:\n",
    "    print(\"ERROR: Corpus file not found!\")\n",
    "    print(\"Run atomization first: lingframe atomize -p <project-name>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count atoms at each level\n",
    "stats = {\n",
    "    \"Themes\": corpus.count_atoms(AtomLevel.THEME),\n",
    "    \"Paragraphs\": corpus.count_atoms(AtomLevel.PARAGRAPH),\n",
    "    \"Sentences\": corpus.count_atoms(AtomLevel.SENTENCE),\n",
    "    \"Words\": corpus.count_atoms(AtomLevel.WORD),\n",
    "    \"Letters\": corpus.count_atoms(AtomLevel.LETTER),\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“Š Corpus Statistics\")\n",
    "print(\"=\" * 40)\n",
    "for level, count in stats.items():\n",
    "    print(f\"{level:15} {count:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all themes\n",
    "def list_themes(corpus):\n",
    "    \"\"\"List all themes with their metadata.\"\"\"\n",
    "    themes = []\n",
    "    for doc in corpus.documents:\n",
    "        for theme in doc.root_atoms:\n",
    "            themes.append({\n",
    "                \"id\": theme.id,\n",
    "                \"title\": theme.metadata.get(\"title\", \"(no title)\"),\n",
    "                \"paragraphs\": len([c for c in theme.children if c.level == AtomLevel.PARAGRAPH]),\n",
    "                \"preview\": theme.text[:100] + \"...\" if len(theme.text) > 100 else theme.text,\n",
    "            })\n",
    "    return themes\n",
    "\n",
    "themes = list_themes(corpus)\n",
    "print(f\"\\nðŸ“– Found {len(themes)} themes\\n\")\n",
    "\n",
    "for i, theme in enumerate(themes[:10], 1):\n",
    "    print(f\"{i}. [{theme['id']}] {theme['title']}\")\n",
    "    print(f\"   Paragraphs: {theme['paragraphs']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore a Specific Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theme_by_index(corpus, index):\n",
    "    \"\"\"Get a theme by its index (0-based).\"\"\"\n",
    "    count = 0\n",
    "    for doc in corpus.documents:\n",
    "        for theme in doc.root_atoms:\n",
    "            if count == index:\n",
    "                return theme\n",
    "            count += 1\n",
    "    return None\n",
    "\n",
    "# Select theme to explore (change index as needed)\n",
    "THEME_INDEX = 0\n",
    "theme = get_theme_by_index(corpus, THEME_INDEX)\n",
    "\n",
    "if theme:\n",
    "    print(f\"\\nðŸ” Theme: {theme.metadata.get('title', theme.id)}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ID: {theme.id}\")\n",
    "    print(f\"\\nContent preview:\")\n",
    "    print(theme.text[:500])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show theme structure\n",
    "if theme:\n",
    "    print(f\"\\nðŸ“‚ Theme Structure\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for para in theme.children:\n",
    "        if para.level == AtomLevel.PARAGRAPH:\n",
    "            sentences = [c for c in para.children if c.level == AtomLevel.SENTENCE]\n",
    "            print(f\"\\n  ðŸ“„ {para.id} ({len(sentences)} sentences)\")\n",
    "            \n",
    "            for sent in sentences[:3]:\n",
    "                preview = sent.text[:60] + \"...\" if len(sent.text) > 60 else sent.text\n",
    "                print(f\"      â†’ {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sentences(corpus, query, limit=10):\n",
    "    \"\"\"Search for sentences containing a query string.\"\"\"\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    def search_recursive(atoms):\n",
    "        for atom in atoms:\n",
    "            if atom.level == AtomLevel.SENTENCE:\n",
    "                if query_lower in atom.text.lower():\n",
    "                    results.append({\n",
    "                        \"id\": atom.id,\n",
    "                        \"text\": atom.text,\n",
    "                        \"theme_id\": atom.theme_id,\n",
    "                    })\n",
    "            search_recursive(atom.children)\n",
    "    \n",
    "    for doc in corpus.documents:\n",
    "        search_recursive(doc.root_atoms)\n",
    "    \n",
    "    return results[:limit]\n",
    "\n",
    "# Search for a term (modify as needed)\n",
    "SEARCH_TERM = \"example\"  # Change this to your search term\n",
    "\n",
    "results = search_sentences(corpus, SEARCH_TERM)\n",
    "print(f\"\\nðŸ”Ž Search results for '{SEARCH_TERM}': {len(results)} found\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. [{result['id']}]\")\n",
    "    print(f\"   {result['text'][:150]}...\" if len(result['text']) > 150 else f\"   {result['text']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_word_frequency(corpus, min_length=4, top_n=20):\n",
    "    \"\"\"Get word frequency across the corpus.\"\"\"\n",
    "    words = []\n",
    "    \n",
    "    def collect_words(atoms):\n",
    "        for atom in atoms:\n",
    "            if atom.level == AtomLevel.SENTENCE:\n",
    "                # Extract words\n",
    "                text_words = re.findall(r'\\b[a-zA-Z]+\\b', atom.text.lower())\n",
    "                words.extend([w for w in text_words if len(w) >= min_length])\n",
    "            collect_words(atom.children)\n",
    "    \n",
    "    for doc in corpus.documents:\n",
    "        collect_words(doc.root_atoms)\n",
    "    \n",
    "    return Counter(words).most_common(top_n)\n",
    "\n",
    "word_freq = get_word_frequency(corpus)\n",
    "print(\"\\nðŸ“Š Top 20 Words (4+ letters)\\n\")\n",
    "for word, count in word_freq:\n",
    "    bar = \"â–ˆ\" * min(count // 5, 30)\n",
    "    print(f\"{word:15} {count:5} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export corpus data as dict for custom analysis\n",
    "corpus_dict = corpus.to_dict()\n",
    "print(f\"Corpus exported as dictionary with {len(corpus_dict)} top-level keys\")\n",
    "print(f\"Keys: {list(corpus_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you've explored the corpus, you can:\n",
    "\n",
    "1. **Run the evaluation analysis**: Open `evaluation.ipynb`\n",
    "2. **Generate visualizations**: Open `visualization.ipynb`\n",
    "3. **Run CLI commands**: `lingframe analyze -p <project-name>`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
